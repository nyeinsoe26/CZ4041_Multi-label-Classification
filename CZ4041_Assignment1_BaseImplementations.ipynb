{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from skmultilearn.ensemble import RakelD, RakelO\n",
    "from sklearn.metrics import make_scorer\n",
    "import skmultilearn.problem_transform as skpt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skmultilearn.adapt as skadapt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def BinaryRelevance(dataset_train_x, dataset_train_y, dataset_test_x, dataset_test_y, base_classif, title):\n",
    "    #print(base_classif)\n",
    "    classifier = skpt.BinaryRelevance(base_classif)\n",
    "    %timeit classifier.fit(dataset_train_x, dataset_train_y)\n",
    "    predictions = classifier.predict(dataset_test_x)\n",
    "    \n",
    "    Metrics_Accuracy(title, predictions ,dataset_test_y)\n",
    "    \n",
    "def ClassifierChain(dataset_train_x, dataset_train_y, dataset_test_x, dataset_test_y, base_classif, title):\n",
    "    classifier = skpt.ClassifierChain(base_classif)\n",
    "    %timeit classifier.fit(dataset_train_x, dataset_train_y)\n",
    "    predictions = classifier.predict(dataset_test_x)\n",
    "    \n",
    "    Metrics_Accuracy(title, predictions ,dataset_test_y)\n",
    "\n",
    "def LabelPowerset(dataset_train_x, dataset_train_y, dataset_test_x, dataset_test_y, base_classif, title):\n",
    "    classifier = skpt.LabelPowerset(base_classif)\n",
    "    %timeit classifier.fit(dataset_train_x, dataset_train_y)\n",
    "    predictions = classifier.predict(dataset_test_x)\n",
    "    \n",
    "    Metrics_Accuracy(title, predictions ,dataset_test_y)\n",
    " \n",
    "def MLkNN(dataset_train_x, dataset_train_y, dataset_test_x, dataset_test_y,num_neighbours, smoothing_param):\n",
    "    x_train = lil_matrix(dataset_train_x).toarray()\n",
    "    y_train = lil_matrix(dataset_train_y).toarray()\n",
    "    x_test = lil_matrix(dataset_test_x).toarray()\n",
    "    \n",
    "    classifier = skadapt.MLkNN(k=num_neighbours,s=smoothing_param)\n",
    "    %timeit classifier.fit(x_train,y_train)\n",
    "    predictions = classifier.predict(x_test)\n",
    "    \n",
    "    text = \"MLkNN w/ k=\" + str(num_neighbours) + \" s=\"+str(smoothing_param)\n",
    "    \n",
    "    Metrics_Accuracy(text, predictions ,dataset_test_y)\n",
    "    \n",
    "def MLARAM(dataset_train_x, dataset_train_y, dataset_test_x, dataset_test_y,num_vigilance, num_threshold):\n",
    "    x_train = lil_matrix(dataset_train_x).toarray()\n",
    "    y_train = lil_matrix(dataset_train_y).toarray()\n",
    "    x_test = lil_matrix(dataset_test_x).toarray()\n",
    "    \n",
    "    #Threshold controls number of prototypes to participate; vigilance controls how large hyperbox is\n",
    "    classifier = skadapt.MLARAM(threshold = num_threshold, vigilance = num_vigilance)\n",
    "    %timeit classifier.fit(x_train,y_train)\n",
    "    predictions = classifier.predict(x_test)\n",
    "    \n",
    "    text = \"MLARAM w/ Threshold = \" + str(num_threshold) + \", Vigilance = \"+ str(num_vigilance)\n",
    "    \n",
    "    Metrics_Accuracy(text, predictions ,dataset_test_y)\n",
    "        \n",
    "    \n",
    "#Random Label Space Partitionining with Label Powerset\n",
    "def RAkELd(dataset_train_x, dataset_train_y, dataset_test_x, dataset_test_y,base_clasif,num_labels):\n",
    "    classifier = RakelD(\n",
    "        base_classifier=base_clasif,\n",
    "        labelset_size=num_labels\n",
    "    )\n",
    "\n",
    "    %timeit classifier.fit(dataset_train_x, dataset_train_y)\n",
    "    predictions = classifier.predict(dataset_test_x)\n",
    "    \n",
    "    Metrics_Accuracy(\"RAkELd\", predictions ,dataset_test_y)\n",
    "    \n",
    "#random overlapping label space division with Label Powerset\n",
    "def RAkELO(dataset_train_x, dataset_train_y, dataset_test_x, dataset_test_y,base_clasif,num_labels, num_models):\n",
    "    classifier = RakelO(\n",
    "        base_classifier=base_clasif,\n",
    "        labelset_size=num_labels,\n",
    "        model_count=num_models\n",
    "    )\n",
    "\n",
    "    %timeit classifier.fit(dataset_train_x, dataset_train_y)\n",
    "    predictions = classifier.predict(dataset_test_x)\n",
    "    \n",
    "    Metrics_Accuracy(\"RAkELO\", predictions ,dataset_test_y)\n",
    "\n",
    "\n",
    "def BRkNNa(dataset_train_x, dataset_train_y, dataset_test_x, dataset_test_y, num_neighbours):\n",
    "    x_train = lil_matrix(dataset_train_x).toarray()\n",
    "    y_train = lil_matrix(dataset_train_y).toarray()\n",
    "    x_test = lil_matrix(dataset_test_x).toarray()\n",
    "    \n",
    "    classifier = skadapt.BRkNNaClassifier(k=num_neighbours)\n",
    "    %timeit classifier.fit(x_train,y_train)\n",
    "    predictions = classifier.predict(x_test)\n",
    "    \n",
    "    text = \"BRkNNa w/ k=\" + str(num_neighbours)\n",
    "    \n",
    "    Metrics_Accuracy(text, predictions ,dataset_test_y)\n",
    "    \n",
    "def BRkNNb(dataset_train_x, dataset_train_y, dataset_test_x, dataset_test_y, num_neighbours):\n",
    "    x_train = lil_matrix(dataset_train_x).toarray()\n",
    "    y_train = lil_matrix(dataset_train_y).toarray()\n",
    "    x_test = lil_matrix(dataset_test_x).toarray()\n",
    "    \n",
    "    classifier = skadapt.BRkNNbClassifier(k=num_neighbours)\n",
    "    %timeit classifier.fit(x_train,y_train)\n",
    "    predictions = classifier.predict(x_test)\n",
    "    \n",
    "    text = \"BRkNNb w/ k=\" + str(num_neighbours)\n",
    "    \n",
    "    Metrics_Accuracy(text, predictions ,dataset_test_y)\n",
    "\n",
    "def TwinMLSVM(dataset_train_x, dataset_train_y, dataset_test_x, dataset_test_y,nc_k, omega):\n",
    "    classifier = skadapt.MLTSVM(c_k = nc_k, sor_omega = omega)\n",
    "    classifier.fit(csr_matrix(dataset_train_x),csr_matrix(dataset_train_y))\n",
    "    predictions = classifier.predict(csr_matrix(dataset_test_x))\n",
    "    \n",
    "    Metrics_Accuracy(\"MLTSVM\", predictions ,dataset_test_y)\n",
    "\n",
    "\n",
    "    \n",
    "def Metrics_Accuracy(classifier,predictions,dataset_test_y):\n",
    "    #results\n",
    "    print(\"Results for \",classifier)\n",
    "    # accuracy\n",
    "    print(\"Accuracy = \",accuracy_score(dataset_test_y,predictions))\n",
    "    # hamming loss\n",
    "    print(\"Hamming loss = \",metrics.hamming_loss(dataset_test_y,predictions))\n",
    "    # log loss\n",
    "    #print(type(predictions)==np.ndarray)\n",
    "    print(\"Log loss = \",metrics.log_loss(dataset_test_y,predictions.toarray() if type(predictions)!=np.ndarray else predictions))\n",
    "    # Exact Match Score\n",
    "    #exact_match_score = np.all(predictions.toarray() == dataset_test_y, axis=1).mean()\n",
    "    #print('Exact match score (Whole row must match):', exact_match_score)\n",
    "    \n",
    "    print(\"\")\n",
    "\n",
    "def FindBestMNBParams(classif, dataset_train_x, dataset_train_y):\n",
    "    rangefloat = [round(x * 0.1, 1) for x in range(1, 11)]\n",
    "    parameters = {\n",
    "        'classifier': [MultinomialNB()],\n",
    "        'classifier__alpha': rangefloat,\n",
    "    }\n",
    "    clf = GridSearchCV(classif, parameters, scoring=make_scorer(metrics.hamming_loss,greater_is_better=False), n_jobs=3)\n",
    "    clf.fit(dataset_train_x, dataset_train_y)\n",
    "    print(clf.best_params_)\n",
    "    #print(pd.DataFrame(clf.cv_results_))\n",
    "    \n",
    "    return clf.best_params_\n",
    "\n",
    "def FindBestSVCParams(classif, dataset_train_x, dataset_train_y):\n",
    "    parameters = {\n",
    "            'classifier': [SVC()],\n",
    "            'classifier__degree': [2,3,4],\n",
    "            'classifier__kernel': ['linear','poly','rbf'],\n",
    "            #'classifier__max_iter': [10000],\n",
    "            #'classifier__loss': ['hinge','squared_hinge'],\n",
    "    }\n",
    "    \n",
    "    clf = GridSearchCV(classif, parameters, scoring=make_scorer(metrics.hamming_loss,greater_is_better=False), n_jobs=3)\n",
    "    clf.fit(dataset_train_x, dataset_train_y)\n",
    "    print(clf.best_params_)\n",
    "    #print(pd.DataFrame(clf.cv_results_))\n",
    "    \n",
    "    return clf.best_params_    \n",
    "    \n",
    "    \n",
    "#estimating best params using hamming loss for multi label problems\n",
    "def FindBestK(classif, dataset_train_x, dataset_train_y):\n",
    "    rangefloatv = [round(x * 0.1, 1) for x in range(5, 11)]\n",
    "    \n",
    "    parameters = {'k': range(1,20), 's': rangefloatv} \n",
    "    if type(classif) == type(skadapt.BRkNNaClassifier()) or type(classif) == type(skadapt.BRkNNbClassifier()):\n",
    "        parameters = {'k': range(1,20)}\n",
    "\n",
    "    clf = GridSearchCV(classif, parameters, scoring=make_scorer(metrics.hamming_loss,greater_is_better=False), n_jobs=2)\n",
    "    clf.fit(lil_matrix(dataset_train_x).toarray(), lil_matrix(dataset_train_y).toarray())\n",
    "    print(clf.best_params_)\n",
    "    return clf.best_params_\n",
    "\n",
    "def FindBestVT(dataset_train_x, dataset_train_y):\n",
    "    rangefloat = [round(x * 0.01, 2) for x in range(1, 11)]\n",
    "    rangefloatv = [round(x * 0.1, 1) for x in range(5, 11)]\n",
    "    parameters = {'threshold': rangefloat, 'vigilance': rangefloatv} #default thres = 0.02, vigi = 0.9\n",
    "\n",
    "    clf = GridSearchCV(skadapt.MLARAM(), parameters, scoring=make_scorer(metrics.hamming_loss,greater_is_better=False), n_jobs=2)\n",
    "    clf.fit(lil_matrix(dataset_train_x).toarray(), lil_matrix(dataset_train_y).toarray())\n",
    "    print(clf.best_params_)\n",
    "    return clf.best_params_\n",
    "\n",
    "def FindCKParam(dataset_train_x, dataset_train_y, dataset_test_x, dataset_test_y):\n",
    "    rangev = [2**i for i in range(-5, 3, 2)]\n",
    "    #introduce back 0 default to rangev\n",
    "    rangev = rangev+ [0]\n",
    "    rangefloat = [round(x * 0.1, 1) for x in range(1, 11)]    \n",
    "    #rangefloat2 = [1e-06, 1e-05]\n",
    "    parameters = {'c_k': rangev, 'sor_omega': rangefloat} \n",
    "    \n",
    "    clf = GridSearchCV(skadapt.MLTSVM(), parameters, scoring=make_scorer(metrics.hamming_loss,greater_is_better=False), n_jobs=2, verbose = 10)\n",
    "    clf.fit(csr_matrix(dataset_train_x),csr_matrix(dataset_train_y))\n",
    "    print(clf.best_params_)\n",
    "    return clf.best_params_\n",
    "    \n",
    "def GridSearchCV_baseRakel(classif, dataset_train_x, dataset_train_y):\n",
    "    #labelset_size denotes the desired size of partition\n",
    "    range_labelset_size = list(range(1,11))\n",
    "    rangefloat = [round(x * 0.1, 1) for x in range(1, 11)]\n",
    "    parameters = [\n",
    "        {\n",
    "            'base_classifier': [GaussianNB()],\n",
    "            'labelset_size': range_labelset_size,\n",
    "        },\n",
    "        {\n",
    "            'base_classifier': [MultinomialNB()],\n",
    "            'base_classifier__alpha': rangefloat, #for smoothing {Additive smoothing parameter NB}\n",
    "            'labelset_size': range_labelset_size,\n",
    "        },\n",
    "        {\n",
    "            'base_classifier': [SVC()],\n",
    "            'base_classifier__kernel': ['rbf','linear','sigmoid'],\n",
    "            'labelset_size': range_labelset_size,\n",
    "        },\n",
    "    ]\n",
    "    print(type(classif) == type(RakelO()))\n",
    "    if (type(classif) == type(RakelO())):\n",
    "        end_range = 10 if dataset_train_y.shape[1]//2 > (3+1) else dataset_train_y.shape[1] #dataset_train_y.shape[1]//2 if dataset_train_y.shape[1]//2 > (3+1) else dataset_train_y.shape[1]\n",
    "        range_labelset_size = list(range(3, end_range))\n",
    "        #starting_range = dataset_train_y.shape[1]//range_labelset_size[0]\n",
    "        range_model_count = list(range(2*dataset_train_y.shape[1],2*dataset_train_y.shape[1]+1)) #[x*2 for x in range((starting_range), (starting_range+1))]#[x*2 for x in range(dataset_train_y.shape[1]//6, dataset_train_y.shape[1]//2)]\n",
    "        print(dataset_train_y.shape[1])\n",
    "        print(range_labelset_size)\n",
    "        print(range_model_count)\n",
    "        parameters = [\n",
    "            {\n",
    "                'base_classifier': [GaussianNB()],\n",
    "                'labelset_size': range_labelset_size,\n",
    "                'model_count': range_model_count,\n",
    "            },\n",
    "            {\n",
    "                'base_classifier': [MultinomialNB()],\n",
    "                'base_classifier__alpha': rangefloat, #for smoothing {Additive smoothing parameter NB}\n",
    "                'labelset_size': range_labelset_size,\n",
    "                'model_count': range_model_count,\n",
    "            },\n",
    "            {\n",
    "                'base_classifier': [SVC()],\n",
    "                'base_classifier__kernel': ['rbf','linear','sigmoid'],\n",
    "                'labelset_size': range_labelset_size,\n",
    "                'model_count': range_model_count,\n",
    "            },\n",
    "        ]\n",
    "    \n",
    "    classifier = GridSearchCV(classif, parameters, scoring=make_scorer(metrics.hamming_loss,greater_is_better=False), n_jobs=3)\n",
    "    classifier.fit(dataset_train_x, dataset_train_y)\n",
    "    print(classifier.best_params_)\n",
    "    return classifier.best_params_\n",
    "\n",
    "def Util_Title(title):\n",
    "    print(\"====================================\",title,\"====================================\")\n",
    "    \n",
    "def Util_ClassifierMethods(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y):\n",
    "    #BR\n",
    "    Util_Title(\"Binary Relevance\")\n",
    "    base_classif = GaussianNB()\n",
    "    BinaryRelevance(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y, base_classif, \"GaussianNB\")\n",
    "\n",
    "    dict_res = FindBestSVCParams(skpt.BinaryRelevance(),dataset_train_x,dataset_train_y)\n",
    "    base_classif = SVC(kernel = dict_res['classifier__kernel'], degree = dict_res['classifier__degree'])\n",
    "    BinaryRelevance(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y, base_classif, \"SVC tuned\")\n",
    "\n",
    "    dict_res = FindBestMNBParams(skpt.BinaryRelevance(),dataset_train_x,dataset_train_y)\n",
    "    base_classif = MultinomialNB(alpha = dict_res['classifier__alpha'])\n",
    "    BinaryRelevance(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y, base_classif, \"MNB tuned\")\n",
    "    \n",
    "    #CC\n",
    "    Util_Title(\"Classifier Chain\")\n",
    "    base_classif = GaussianNB()\n",
    "    ClassifierChain(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y, base_classif, \"GaussianNB\")\n",
    "\n",
    "    dict_res = FindBestSVCParams(skpt.ClassifierChain(),dataset_train_x,dataset_train_y)\n",
    "    base_classif = SVC(kernel = dict_res['classifier__kernel'], degree = dict_res['classifier__degree'])\n",
    "    ClassifierChain(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y, base_classif, \"SVC tuned\")\n",
    "\n",
    "    dict_res = FindBestMNBParams(skpt.ClassifierChain(),dataset_train_x,dataset_train_y)\n",
    "    base_classif = MultinomialNB(alpha = dict_res['classifier__alpha'])\n",
    "    ClassifierChain(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y, base_classif, \"MNB tuned\")\n",
    "\n",
    "    #LP\n",
    "    Util_Title(\"Label Powerset\")\n",
    "    base_classif = GaussianNB()\n",
    "    LabelPowerset(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y, base_classif, \"GaussianNB\")\n",
    "\n",
    "    dict_res = FindBestSVCParams(skpt.LabelPowerset(),dataset_train_x,dataset_train_y)\n",
    "    base_classif = SVC(kernel = dict_res['classifier__kernel'], degree = dict_res['classifier__degree'])\n",
    "    LabelPowerset(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y, base_classif, \"SVC tuned\")\n",
    "\n",
    "    dict_res = FindBestMNBParams(skpt.LabelPowerset(),dataset_train_x,dataset_train_y)\n",
    "    base_classif = MultinomialNB(alpha = dict_res['classifier__alpha'])\n",
    "    LabelPowerset(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y, base_classif, \"MNB tuned\")\n",
    "    \n",
    "    #MLkNN\n",
    "    Util_Title(\"MLkNN\")\n",
    "    dict_res= FindBestK(skadapt.MLkNN(), dataset_train_x,dataset_train_y)\n",
    "    MLkNN(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y,dict_res['k'],dict_res['s'])\n",
    "\n",
    "    #MLARAM\n",
    "    Util_Title(\"MLARAM\")\n",
    "    dict_res = FindBestVT(dataset_train_x,dataset_train_y)\n",
    "    MLARAM(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y,dict_res['vigilance'],dict_res['threshold'])\n",
    "\n",
    "    #BRkNNa\n",
    "    Util_Title(\"BRkNNa\")\n",
    "    dict_res= FindBestK(skadapt.BRkNNaClassifier(), dataset_train_x,dataset_train_y)\n",
    "    BRkNNa(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y,dict_res['k'])\n",
    "    \n",
    "    #BRkNNb\n",
    "    Util_Title(\"BRkNNb\")\n",
    "    dict_res= FindBestK(skadapt.BRkNNbClassifier(), dataset_train_x,dataset_train_y)\n",
    "    BRkNNb(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y,dict_res['k'])\n",
    "    \n",
    "    #RAkELD\n",
    "    Util_Title(\"RAkELd\")\n",
    "    dict_res = GridSearchCV_baseRakel(RakelD(),dataset_train_x,dataset_train_y)\n",
    "    RAkELd(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y,dict_res['base_classifier'],dict_res['labelset_size'])\n",
    "    \n",
    "    #RAkELo\n",
    "    Util_Title(\"RAkELo\")\n",
    "    dict_res = GridSearchCV_baseRakel(RakelO(),dataset_train_x,dataset_train_y)\n",
    "    RAkELO(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y,dict_res['base_classifier'],dict_res['labelset_size'],dict_res['model_count'])\n",
    "\n",
    "    #MLTSVM\n",
    "    Util_Title(\"MLTSVM\")\n",
    "    dict_res = FindCKParam(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y)\n",
    "    TwinMLSVM(dataset_train_x,dataset_train_y,dataset_test_x,dataset_test_y,dict_res['c_k'],dict_res['sor_omega'])\n",
    "\n",
    "def Util_ClassifierMethodsBookmarks(train_x, y_train, test_x, y_test):    \n",
    "    #Scale negatives for BR/ CC and LP for MultinomialNB\n",
    "    x_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "    train_x_scaledb = x_scaler.fit_transform(train_x)\n",
    "    test_x_scaledb = x_scaler.fit_transform(test_x)\n",
    "\n",
    "    #BR\n",
    "    Util_Title(\"Binary Relevance\")\n",
    "    base_classif = GaussianNB()\n",
    "    BinaryRelevance(train_x_scaledb, y_train, test_x_scaledb, y_test, base_classif, \"GaussianNB\")\n",
    "\n",
    "    dict_res = FindBestSVCParams(skpt.BinaryRelevance(),train_x_scaledb, y_train)\n",
    "    base_classif = SVC(kernel = dict_res['classifier__kernel'], degree = dict_res['classifier__degree'])\n",
    "    BinaryRelevance(train_x_scaledb, y_train, test_x_scaledb, y_test, base_classif, \"SVC tuned\")\n",
    "\n",
    "    dict_res = FindBestMNBParams(skpt.BinaryRelevance(),train_x_scaledb,y_train)\n",
    "    base_classif = MultinomialNB(alpha = dict_res['classifier__alpha'])\n",
    "    BinaryRelevance(train_x_scaledb, y_train, test_x_scaledb, y_test, base_classif, \"MNB tuned\")\n",
    "    \n",
    "    #CC\n",
    "    Util_Title(\"Classifier Chain\")\n",
    "    base_classif = GaussianNB()\n",
    "    ClassifierChain(train_x_scaledb, y_train, test_x_scaledb, y_test, base_classif, \"GaussianNB\")\n",
    "\n",
    "    dict_res = FindBestSVCParams(skpt.ClassifierChain(),train_x_scaledb, y_train)\n",
    "    base_classif = SVC(kernel = dict_res['classifier__kernel'], degree = dict_res['classifier__degree'])\n",
    "    ClassifierChain(train_x_scaledb, y_train, test_x_scaledb, y_test, base_classif, \"SVC tuned\")\n",
    "\n",
    "    dict_res = FindBestMNBParams(skpt.ClassifierChain(),train_x_scaledb, y_train)\n",
    "    base_classif = MultinomialNB(alpha = dict_res['classifier__alpha'])\n",
    "    ClassifierChain(train_x_scaledb, y_train, test_x_scaledb, y_test, base_classif, \"MNB tuned\")\n",
    "\n",
    "    #LP\n",
    "    Util_Title(\"Label Powerset\")\n",
    "    base_classif = GaussianNB()\n",
    "    LabelPowerset(train_x_scaledb, y_train, test_x_scaledb, y_test, base_classif, \"GaussianNB\")\n",
    "\n",
    "    dict_res = FindBestSVCParams(skpt.LabelPowerset(),train_x_scaledb, y_train)\n",
    "    base_classif = SVC(kernel = dict_res['classifier__kernel'], degree = dict_res['classifier__degree'])\n",
    "    LabelPowerset(train_x_scaledb, y_train, test_x_scaledb, y_test, base_classif, \"SVC tuned\")\n",
    "\n",
    "    dict_res = FindBestMNBParams(skpt.LabelPowerset(),train_x_scaledb, y_train)\n",
    "    base_classif = MultinomialNB(alpha = dict_res['classifier__alpha'])\n",
    "    LabelPowerset(train_x_scaledb, y_train, test_x_scaledb, y_test, base_classif, \"MNB tuned\")\n",
    "    \n",
    "    #RAkELo\n",
    "    Util_Title(\"RAkELo\")\n",
    "    lbs_size = 3\n",
    "    mod_count = 4\n",
    "    RAkELO(train_x, y_train,test_x, y_test, LinearSVC(max_iter=500,verbose=1),lbs_size,mod_count)\n",
    "\n",
    "    #RAkELd\n",
    "    lbs_size = 3\n",
    "    RAkELd(train_x, y_train, test_x, y_test, LinearSVC(verbose =2), lbs_size)\n",
    "\n",
    "    #MLkNN\n",
    "    base_classif = skadapt.MLkNN()\n",
    "    k = 10\n",
    "    s = 1\n",
    "    MLkNN(train_x,y_train,test_x, y_test,k,s)\n",
    "\n",
    "    #MLARAM\n",
    "    v = 0.95\n",
    "    t = 0.05\n",
    "    dict_res = FindBestVT(train_x, y_train)\n",
    "    MLARAM(train_x,y_train,test_x, y_test,dict_res['vigilance'],dict_res['threshold'])\n",
    "\n",
    "    #BRkNNa\n",
    "    dict_res= FindBestK(skadapt.BRkNNaClassifier(), train_x, y_train)\n",
    "    BRkNNa(train_x,y_train,test_x, y_test,dict_res['k'])\n",
    "\n",
    "    #BRkNNb\n",
    "    dict_res= FindBestK(skadapt.BRkNNbClassifier(), train_x, y_train)\n",
    "    BRkNNb(train_x,y_train,test_x, y_test,dict_res['k'])\n",
    "\n",
    "    #MLTSVM\n",
    "    #Test for 0 \n",
    "    #TwinMLSVM(train_x,y_train,test_x,y_test,0,1)\n",
    "    #Test for 0.125\n",
    "    TwinMLSVM(train_x,y_train,test_x,y_test,0.125,1)\n",
    "    #Test for 0.25\n",
    "    #TwinMLSVM(train_x,y_train,test_x,y_test,0.25,1)    \n",
    "    \n",
    "def LoadEmotionsDataset(path):\n",
    "    #Emotions Dataset\n",
    "    #emotions\n",
    "    print(\"Load Emotions dataset\")\n",
    "    emotions = pd.read_csv(path)\n",
    "\n",
    "    #scale based on columns before split\n",
    "    mms = preprocessing.MinMaxScaler()\n",
    "    emotions.iloc[:,0:72] = mms.fit_transform(emotions.iloc[:,0:72])\n",
    "\n",
    "    #split dataset\n",
    "    dataset_train_emotions, dataset_test_emotions = train_test_split(emotions,random_state=42, test_size=0.20, shuffle=True)\n",
    "\n",
    "    dataset_train_x_emotions = dataset_train_emotions.iloc[:,0:72]\n",
    "    dataset_train_y_emotions = dataset_train_emotions.iloc[:,-6:]\n",
    "\n",
    "    dataset_test_x_emotions = dataset_test_emotions.iloc[:,0:72]\n",
    "    dataset_test_y_emotions = dataset_test_emotions.iloc[:,-6:]\n",
    "    \n",
    "    return dataset_train_x_emotions,dataset_train_y_emotions,dataset_test_x_emotions,dataset_test_y_emotions\n",
    "\n",
    "def LoadYeastDataset(path): \n",
    "    print(\"Load Yeast dataset\")\n",
    "    yeast = pd.read_csv(path)\n",
    "\n",
    "    #scale based on columns before split\n",
    "    mms = preprocessing.MinMaxScaler()\n",
    "    yeast.iloc[:,0:103] = mms.fit_transform(yeast.iloc[:,0:103])\n",
    "\n",
    "    #split dataset\n",
    "    dataset_train_yeast, dataset_test_yeast = train_test_split(yeast,random_state=42, test_size=0.20, shuffle=True)\n",
    "\n",
    "    dataset_train_x_yeast = dataset_train_yeast.iloc[:,0:103]\n",
    "    dataset_train_y_yeast = dataset_train_yeast.iloc[:,-14:]\n",
    "\n",
    "    dataset_test_x_yeast = dataset_test_yeast.iloc[:,0:103]\n",
    "    dataset_test_y_yeast = dataset_test_yeast.iloc[:,-14:]\n",
    "    \n",
    "    return dataset_train_x_yeast, dataset_train_y_yeast, dataset_test_x_yeast, dataset_test_y_yeast\n",
    "\n",
    "def LoadBookmarksDataset(path):\n",
    "    #bookmarks 1/10\n",
    "    print(\"Bookmarks dataset\")\n",
    "    book = pd.read_csv(path)\n",
    "    book1, book2 = train_test_split(book, random_state=42, test_size=0.90, shuffle=True)\n",
    "    print(book1.shape)\n",
    "    print(book2.shape)\n",
    "    \n",
    "    bookmark_train, bookmark_test = train_test_split(book1, random_state=42, test_size=0.20, shuffle=True)\n",
    "    x_train = bookmark_train.iloc[:,0:2150]\n",
    "    y_train = bookmark_train.iloc[:,-208:]\n",
    "\n",
    "    x_test = bookmark_test.iloc[:,0:2150]\n",
    "    y_test = bookmark_test.iloc[:,-208:]\n",
    "    x_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "    x_scaled_train =  np.float32(x_scaler.fit_transform(x_train))\n",
    "    x_scaled_test = np.float32(x_scaler.fit_transform(x_test))\n",
    "    print(\"x_scaled_train shape: {}, x_scaled_test shape: {}\".format(x_scaled_train.shape,x_scaled_test.shape))\n",
    "    print(\"x_scaled_train type: {}, x_scaled_test type: {}\".format(type(x_scaled_train),type(x_scaled_test)))\n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(0.9)\n",
    "    pca.fit(x_scaled_train)\n",
    "    train_x = pca.transform(x_scaled_train)\n",
    "    test_x = pca.transform(x_scaled_test)\n",
    "    print(\"train_x shape: {}, test_x: {}\".format(train_x.shape,test_x.shape))\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    print(\"y_train shape: {}, y_test shape: {}\".format(y_train.shape,y_test.shape))\n",
    "    print(\"y_train type: {}, y_test type: {}\".format(type(y_train),type(y_test)))\n",
    "    print(\"y_train[0]: {}\".format(y_train[0]))\n",
    "    \n",
    "    return train_x, y_train, test_x, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Emotions dataset\n",
      "Emotions Dataset\n",
      "==================================== Binary Relevance ====================================\n",
      "9.2 ms ± 646 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Results for  GaussianNB\n",
      "Accuracy =  0.23529411764705882\n",
      "Hamming loss =  0.242296918767507\n",
      "Log loss =  17.748562300103703\n",
      "\n",
      "{'classifier': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=2, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False), 'classifier__degree': 2, 'classifier__kernel': 'rbf'}\n",
      "83 ms ± 1.24 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Results for  SVC tuned\n",
      "Accuracy =  0.31932773109243695\n",
      "Hamming loss =  0.17507002801120447\n",
      "Log loss =  19.842430799140388\n",
      "\n",
      "{'classifier': MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True), 'classifier__alpha': 0.2}\n",
      "9.98 ms ± 376 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Results for  MNB tuned\n",
      "Accuracy =  0.18487394957983194\n",
      "Hamming loss =  0.22969187675070027\n",
      "Log loss =  13.796195742115925\n",
      "\n",
      "==================================== Classifier Chain ====================================\n",
      "10.8 ms ± 349 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Results for  GaussianNB\n",
      "Accuracy =  0.2184873949579832\n",
      "Hamming loss =  0.23669467787114845\n",
      "Log loss =  17.729774152665914\n",
      "\n",
      "{'classifier': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=2, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False), 'classifier__degree': 2, 'classifier__kernel': 'rbf'}\n",
      "80.9 ms ± 1.27 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Results for  SVC tuned\n",
      "Accuracy =  0.35294117647058826\n",
      "Hamming loss =  0.19187675070028012\n",
      "Log loss =  21.021862144997353\n",
      "\n",
      "{'classifier': MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True), 'classifier__alpha': 0.1}\n",
      "11.7 ms ± 822 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Results for  MNB tuned\n",
      "Accuracy =  0.24369747899159663\n",
      "Hamming loss =  0.24649859943977592\n",
      "Log loss =  25.950376040792975\n",
      "\n",
      "==================================== Label Powerset ====================================\n",
      "6.38 ms ± 118 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Results for  GaussianNB\n",
      "Accuracy =  0.24369747899159663\n",
      "Hamming loss =  0.24649859943977592\n",
      "Log loss =  28.74001269861988\n",
      "\n",
      "{'classifier': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=2, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False), 'classifier__degree': 2, 'classifier__kernel': 'rbf'}\n",
      "48.9 ms ± 1.36 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Results for  SVC tuned\n",
      "Accuracy =  0.37815126050420167\n",
      "Hamming loss =  0.18207282913165265\n",
      "Log loss =  16.337664355216496\n",
      "\n",
      "{'classifier': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'classifier__alpha': 1.0}\n",
      "5.42 ms ± 258 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Results for  MNB tuned\n",
      "Accuracy =  0.33613445378151263\n",
      "Hamming loss =  0.22268907563025211\n",
      "Log loss =  21.24474485870703\n",
      "\n",
      "==================================== MLkNN ====================================\n",
      "{'k': 18, 's': 0.5}\n",
      "368 ms ± 17.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Results for  MLkNN w/ k=18 s=0.5\n",
      "Accuracy =  0.24369747899159663\n",
      "Hamming loss =  0.20588235294117646\n",
      "Log loss =  24.94522546540537\n",
      "\n",
      "==================================== MLARAM ====================================\n",
      "{'threshold': 0.08, 'vigilance': 0.9}\n",
      "1.92 s ± 730 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Results for  MLARAM w/ Threshold = 0.08, Vigilance = 0.9\n",
      "Accuracy =  0.2857142857142857\n",
      "Hamming loss =  0.21008403361344538\n",
      "Log loss =  19.356077640115846\n",
      "\n",
      "==================================== BRkNNa ====================================\n",
      "{'k': 14}\n",
      "4.63 ms ± 158 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Results for  BRkNNa w/ k=14\n",
      "Accuracy =  0.2773109243697479\n",
      "Hamming loss =  0.19187675070028012\n",
      "Log loss =  21.614871213511798\n",
      "\n",
      "==================================== BRkNNb ====================================\n",
      "{'k': 5}\n",
      "4.69 ms ± 272 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Results for  BRkNNb w/ k=5\n",
      "Accuracy =  0.05042016806722689\n",
      "Hamming loss =  0.3795518207282913\n",
      "Log loss =  38.88485398422384\n",
      "\n",
      "==================================== RAkELd ====================================\n",
      "False\n",
      "{'base_classifier': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False), 'base_classifier__kernel': 'rbf', 'labelset_size': 1}\n",
      "92.7 ms ± 1.92 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Results for  RAkELd\n",
      "Accuracy =  0.31932773109243695\n",
      "Hamming loss =  0.17507002801120447\n",
      "Log loss =  19.842430799140388\n",
      "\n",
      "==================================== RAkELo ====================================\n",
      "True\n",
      "6\n",
      "[3, 4, 5]\n",
      "[12]\n",
      "{'base_classifier': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False), 'base_classifier__kernel': 'rbf', 'labelset_size': 3, 'model_count': 12}\n",
      "365 ms ± 5.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Results for  RAkELO\n",
      "Accuracy =  0.35294117647058826\n",
      "Hamming loss =  0.18067226890756302\n",
      "Log loss =  22.32195139077681\n",
      "\n",
      "==================================== MLTSVM ====================================\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=2)]: Done  57 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=2)]: Done  68 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=2)]: Done  81 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=2)]: Done  94 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done 109 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=2)]: Done 141 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=2)]: Done 177 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=2)]: Done 217 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=2)]: Done 238 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=2)]: Done 250 out of 250 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c_k': 0.5, 'sor_omega': 0.5}\n",
      "Results for  MLTSVM\n",
      "Accuracy =  0.23529411764705882\n",
      "Hamming loss =  0.22128851540616246\n",
      "Log loss =  19.654737869842275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/K/Desktop/Assignment1/\"\n",
    "dataset_train_x_emotions,dataset_train_y_emotions,dataset_test_x_emotions,dataset_test_y_emotions = LoadEmotionsDataset(path+\"emotions.csv\") #r\"C:/Users/K/Desktop/Assignment1/emotions.csv\")\n",
    "\n",
    "print(\"Emotions Dataset\")\n",
    "Util_ClassifierMethods(dataset_train_x_emotions,dataset_train_y_emotions,dataset_test_x_emotions,dataset_test_y_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Yeast dataset\n",
      "Yeast Dataset\n",
      "==================================== Binary Relevance ====================================\n",
      "96.1 ms ± 1.63 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Results for  GaussianNB\n",
      "Accuracy =  0.09917355371900827\n",
      "Hamming loss =  0.30283353010625735\n",
      "Log loss =  65.19914296904747\n",
      "\n",
      "{'classifier': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=2, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False), 'classifier__degree': 2, 'classifier__kernel': 'rbf'}\n",
      "4.39 s ± 251 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Results for  SVC tuned\n",
      "Accuracy =  0.18801652892561985\n",
      "Hamming loss =  0.18654073199527746\n",
      "Log loss =  67.03054392022239\n",
      "\n",
      "{'classifier': MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True), 'classifier__alpha': 0.1}\n",
      "69.3 ms ± 993 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Results for  MNB tuned\n",
      "Accuracy =  0.014462809917355372\n",
      "Hamming loss =  0.2262396694214876\n",
      "Log loss =  95.2356950892885\n",
      "\n",
      "==================================== Classifier Chain ====================================\n",
      "129 ms ± 858 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Results for  GaussianNB\n",
      "Accuracy =  0.09090909090909091\n",
      "Hamming loss =  0.31729634002361273\n",
      "Log loss =  67.37627753072266\n",
      "\n",
      "{'classifier': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=2, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False), 'classifier__degree': 2, 'classifier__kernel': 'rbf'}\n",
      "2.96 s ± 201 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Results for  SVC tuned\n",
      "Accuracy =  0.22107438016528927\n",
      "Hamming loss =  0.2001180637544274\n",
      "Log loss =  65.94675102057282\n",
      "\n",
      "{'classifier': MultinomialNB(alpha=0.9, class_prior=None, fit_prior=True), 'classifier__alpha': 0.9}\n",
      "126 ms ± 21.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Results for  MNB tuned\n",
      "Accuracy =  0.06818181818181818\n",
      "Hamming loss =  0.23878394332939787\n",
      "Log loss =  85.07557246529349\n",
      "\n",
      "==================================== Label Powerset ====================================\n",
      "55.8 ms ± 1.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Results for  GaussianNB\n",
      "Accuracy =  0.1756198347107438\n",
      "Hamming loss =  0.24321133412042503\n",
      "Log loss =  65.31607274155078\n",
      "\n",
      "{'classifier': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=2, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False), 'classifier__degree': 2, 'classifier__kernel': 'rbf'}\n",
      "2.04 s ± 32.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Results for  SVC tuned\n",
      "Accuracy =  0.2665289256198347\n",
      "Hamming loss =  0.20056080283353012\n",
      "Log loss =  61.3614143059135\n",
      "\n",
      "{'classifier': MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True), 'classifier__alpha': 0.1}\n",
      "50.3 ms ± 1.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Results for  MNB tuned\n",
      "Accuracy =  0.1797520661157025\n",
      "Hamming loss =  0.23996458087367178\n",
      "Log loss =  68.34131349060709\n",
      "\n",
      "==================================== MLkNN ====================================\n",
      "{'k': 18, 's': 0.7}\n",
      "4.94 s ± 1.15 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Results for  MLkNN w/ k=18 s=0.7\n",
      "Accuracy =  0.1859504132231405\n",
      "Hamming loss =  0.19259149940968123\n",
      "Log loss =  64.14271555537948\n",
      "\n",
      "==================================== MLARAM ====================================\n",
      "{'threshold': 0.07, 'vigilance': 0.7}\n",
      "1.54 s ± 499 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Results for  MLARAM w/ Threshold = 0.07, Vigilance = 0.7\n",
      "Accuracy =  0.16115702479338842\n",
      "Hamming loss =  0.20041322314049587\n",
      "Log loss =  66.48396247530553\n",
      "\n",
      "==================================== BRkNNa ====================================\n",
      "{'k': 19}\n",
      "65.3 ms ± 897 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Results for  BRkNNa w/ k=19\n",
      "Accuracy =  0.1859504132231405\n",
      "Hamming loss =  0.1878689492325856\n",
      "Log loss =  63.72172339623755\n",
      "\n",
      "==================================== BRkNNb ====================================\n",
      "{'k': 19}\n",
      "62.4 ms ± 1.63 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Results for  BRkNNb w/ k=19\n",
      "Accuracy =  0.002066115702479339\n",
      "Hamming loss =  0.32615112160566706\n",
      "Log loss =  84.82771553187013\n",
      "\n",
      "==================================== RAkELd ====================================\n",
      "False\n",
      "{'base_classifier': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False), 'base_classifier__kernel': 'rbf', 'labelset_size': 1}\n",
      "5.01 s ± 340 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Results for  RAkELd\n",
      "Accuracy =  0.18801652892561985\n",
      "Hamming loss =  0.18654073199527746\n",
      "Log loss =  67.03054392022239\n",
      "\n",
      "==================================== RAkELo ====================================\n",
      "True\n",
      "14\n",
      "[3, 4, 5, 6, 7, 8, 9]\n",
      "[28]\n",
      "{'base_classifier': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False), 'base_classifier__kernel': 'rbf', 'labelset_size': 3, 'model_count': 28}\n",
      "18.6 s ± 309 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Results for  RAkELO\n",
      "Accuracy =  0.21487603305785125\n",
      "Hamming loss =  0.1852125147579693\n",
      "Log loss =  63.40569694990404\n",
      "\n",
      "==================================== MLTSVM ====================================\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=2)]: Done  57 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=2)]: Done  68 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=2)]: Done  81 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=2)]: Done  94 tasks      | elapsed: 23.2min\n",
      "[Parallel(n_jobs=2)]: Done 109 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed: 27.8min\n",
      "[Parallel(n_jobs=2)]: Done 141 tasks      | elapsed: 30.1min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 32.1min\n",
      "[Parallel(n_jobs=2)]: Done 177 tasks      | elapsed: 36.4min\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed: 40.4min\n",
      "[Parallel(n_jobs=2)]: Done 217 tasks      | elapsed: 50.3min\n",
      "[Parallel(n_jobs=2)]: Done 238 tasks      | elapsed: 61.9min\n",
      "[Parallel(n_jobs=2)]: Done 250 out of 250 | elapsed: 69.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c_k': 0.5, 'sor_omega': 0.1}\n",
      "Results for  MLTSVM\n",
      "Accuracy =  0.03925619834710744\n",
      "Hamming loss =  0.2767119244391972\n",
      "Log loss =  71.23620112149082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#yeast\n",
    "path = \"C:/Users/K/Desktop/Assignment1/\"\n",
    "dataset_train_x_yeast, dataset_train_y_yeast, dataset_test_x_yeast, dataset_test_y_yeast = LoadYeastDataset(path+\"yeast.csv\")\n",
    "\n",
    "print(\"Yeast Dataset\")\n",
    "Util_ClassifierMethods(dataset_train_x_yeast,dataset_train_y_yeast,dataset_test_x_yeast,dataset_test_y_yeast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bookmarks dataset\n",
      "(8785, 2358)\n",
      "(79071, 2358)\n",
      "x_scaled_train shape: (7028, 2150), x_scaled_test shape: (1757, 2150)\n",
      "x_scaled_train type: <class 'numpy.ndarray'>, x_scaled_test type: <class 'numpy.ndarray'>\n",
      "train_x shape: (7028, 956), test_x: (1757, 956)\n",
      "y_train shape: (7028, 208), y_test shape: (1757, 208)\n",
      "y_train type: <class 'numpy.ndarray'>, y_test type: <class 'numpy.ndarray'>\n",
      "y_train[0]: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "(7028, 956)\n",
      "(7028, 208)\n",
      "(1757, 956)\n",
      "(1757, 208)\n",
      "Bookmarks Dataset\n"
     ]
    }
   ],
   "source": [
    "#bookmarks 1/10\n",
    "path = \"C:/Users/K/Desktop/Assignment1/\"\n",
    "train_x, y_train, test_x, y_test = LoadBookmarksDataset(path+\"bookmarks.csv\")\n",
    "print(train_x.shape)\n",
    "print(y_train.shape)\n",
    "print(test_x.shape)\n",
    "print(y_test.shape)\n",
    "      \n",
    "print(\"Bookmarks Dataset\")\n",
    "Util_ClassifierMethodsBookmarks(train_x, y_train, test_x, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
